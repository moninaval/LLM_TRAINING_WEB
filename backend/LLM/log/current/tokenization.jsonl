[{"sample_index": 0, "sample": {"input_text": " literature emerged. Known as detective fiction, it captivated readers with its intricate plots and brilliant, eccentric protagonists. Arthur Conan Doyle's Sherlock Holmes and Agatha Christie's Hercule Poirot are arguably the most famous examples. They set the standard for a genre that continues to thrive.<|endoftext|><|endoftext|>The capital city of France is Paris. It is home to the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral. The city's official motto is \"Fluctuat nec mergitur,\" which means \"Tossed but not sunk.\" It's a testament to the city's resilience throughout history.", "tokens": ["Ġliterature", "Ġemerged", ".", "ĠKnown", "Ġas", "Ġdetective", "Ġfiction", ",", "Ġit", "Ġcapt", "ivated", "Ġreaders", "Ġwith", "Ġits", "Ġintricate", "Ġplots", "Ġand", "Ġbrilliant", ",", "Ġeccentric", "Ġprotagonists", ".", "ĠArthur", "ĠConan", "ĠDoyle", "'s", "ĠSherlock", "ĠHolmes", "Ġand", "ĠAg", "atha", "ĠChristie", "'s", "ĠHer", "cule", "ĠPo", "iro", "t", "Ġare", "Ġarguably", "Ġthe", "Ġmost", "Ġfamous", "Ġexamples", ".", "ĠThey", "Ġset", "Ġthe", "Ġstandard", "Ġfor", "Ġa", "Ġgenre", "Ġthat", "Ġcontinues", "Ġto", "Ġthrive", ".", "<|endoftext|>", "<|endoftext|>", "The", "Ġcapital", "Ġcity", "Ġof", "ĠFrance", "Ġis", "ĠParis", ".", "ĠIt", "Ġis", "Ġhome", "Ġto", "Ġthe", "ĠE", "iff", "el", "ĠTower", ",", "Ġthe", "ĠLou", "vre", "ĠMuseum", ",", "Ġand", "ĠNotre", "-", "D", "ame", "ĠCathedral", ".", "ĠThe", "Ġcity", "'s", "Ġofficial", "Ġmotto", "Ġis", "Ġ\"", "F", "lu", "ct", "u", "at", "Ġnec", "Ġmer", "git", "ur", ",\"", "Ġwhich", "Ġmeans", "Ġ\"", "T", "oss", "ed", "Ġbut", "Ġnot", "Ġsunk", ".\"", "ĠIt", "'s", "Ġa", "Ġtestament", "Ġto", "Ġthe", "Ġcity", "'s", "Ġresilience", "Ġthroughout", "Ġhistory", "."], "ids": [9285, 9349, 13, 29454, 355, 20775, 10165, 11, 340, 3144, 30829, 7183, 351, 663, 28746, 21528, 290, 10457, 11, 29303, 39558, 13, 13514, 31634, 31233, 338, 25730, 17628, 290, 2449, 30921, 16929, 338, 2332, 23172, 7695, 7058, 83, 389, 15242, 262, 749, 5863, 6096, 13, 1119, 900, 262, 3210, 329, 257, 12121, 326, 4477, 284, 22191, 13, 50256, 50256, 464, 3139, 1748, 286, 4881, 318, 6342, 13, 632, 318, 1363, 284, 262, 412, 733, 417, 8765, 11, 262, 4768, 43933, 9594, 11, 290, 23382, 12, 35, 480, 32536, 13, 383, 1748, 338, 1743, 33600, 318, 366, 37, 2290, 310, 84, 265, 27576, 4017, 18300, 333, 553, 543, 1724, 366, 51, 793, 276, 475, 407, 24790, 526, 632, 338, 257, 29210, 284, 262, 1748, 338, 31307, 3690, 2106, 13], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "formula": "x → tokenizer(x) → tokens → ids → pad/truncate→T → attention_mask"}, {"sample_index": 1, "sample": {"input_text": "<|endoftext|><|endoftext|>\"I can't believe it's already November,\" she sighed, looking out the window at the falling leaves. \"It feels like summer was just yesterday.\" He nodded in agreement, stirring his coffee. \"Time really does fly when you're busy.\"<|endoftext|><|endoftext|>Here is a simple Python script:<|endoftext|><|endoftext|>Python<|endoftext|><|endoftext|>def fibonacci(n):<|endoftext|>    a, b = 0, 1<|endoftext|>    for _ in range(n):<|endoftext|>        print(a, end=' ')<|endoftext|>        a, b = b, a + b<|endoftext|><|endoftext|>fibonacci(10)<|endoftext|>The solar system consists of eight", "tokens": ["<|endoftext|>", "<|endoftext|>", "\"", "I", "Ġcan", "'t", "Ġbelieve", "Ġit", "'s", "Ġalready", "ĠNovember", ",\"", "Ġshe", "Ġsighed", ",", "Ġlooking", "Ġout", "Ġthe", "Ġwindow", "Ġat", "Ġthe", "Ġfalling", "Ġleaves", ".", "Ġ\"", "It", "Ġfeels", "Ġlike", "Ġsummer", "Ġwas", "Ġjust", "Ġyesterday", ".\"", "ĠHe", "Ġnodded", "Ġin", "Ġagreement", ",", "Ġstirring", "Ġhis", "Ġcoffee", ".", "Ġ\"", "Time", "Ġreally", "Ġdoes", "Ġfly", "Ġwhen", "Ġyou", "'re", "Ġbusy", ".\"", "<|endoftext|>", "<|endoftext|>", "Here", "Ġis", "Ġa", "Ġsimple", "ĠPython", "Ġscript", ":", "<|endoftext|>", "<|endoftext|>", "Python", "<|endoftext|>", "<|endoftext|>", "def", "Ġfib", "on", "acci", "(", "n", "):", "<|endoftext|>", "    ", "a", ",", "Ġb", "Ġ=", "Ġ0", ",", "Ġ1", "<|endoftext|>", "    ", "for", "Ġ_", "Ġin", "Ġrange", "(", "n", "):", "<|endoftext|>", "        ", "print", "(", "a", ",", "Ġend", "='", "Ġ'", ")", "<|endoftext|>", "        ", "a", ",", "Ġb", "Ġ=", "Ġb", ",", "Ġa", "Ġ+", "Ġb", "<|endoftext|>", "<|endoftext|>", "f", "ib", "on", "acci", "(", "10", ")", "<|endoftext|>", "The", "Ġsolar", "Ġsystem", "Ġconsists", "Ġof", "Ġeight"], "ids": [50256, 50256, 1, 40, 460, 470, 1975, 340, 338, 1541, 3389, 553, 673, 21893, 11, 2045, 503, 262, 4324, 379, 262, 7463, 5667, 13, 366, 1026, 5300, 588, 3931, 373, 655, 7415, 526, 679, 14464, 287, 4381, 11, 26547, 465, 6891, 13, 366, 7575, 1107, 857, 6129, 618, 345, 821, 8179, 526, 50256, 50256, 4342, 318, 257, 2829, 11361, 4226, 25, 50256, 50256, 37906, 50256, 50256, 4299, 12900, 261, 44456, 7, 77, 2599, 50256, 50284, 64, 11, 275, 796, 657, 11, 352, 50256, 50284, 1640, 4808, 287, 2837, 7, 77, 2599, 50256, 50280, 4798, 7, 64, 11, 886, 11639, 705, 8, 50256, 50280, 64, 11, 275, 796, 275, 11, 257, 1343, 275, 50256, 50256, 69, 571, 261, 44456, 7, 940, 8, 50256, 464, 6591, 1080, 10874, 286, 3624], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "formula": "x → tokenizer(x) → tokens → ids → pad/truncate→T → attention_mask"}]
